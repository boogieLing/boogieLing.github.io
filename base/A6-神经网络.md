# 神经网络

## LSTM普通

公式以及结构

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190122110244661.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FsZXhieXk=,size_16,color_FFFFFF,t_70)

第一个门（（forget gate layer））：决定我们要扔掉哪些信息

第二个门（updating gate）：用来决定我们要增加哪些新的信息

第三个门（Output gate），该门用来计算a^<t>^,然后a^<t>^用来计算该单元的输出y

------

## 常用库

Tensorflow：机器学习框架

Keras：更简单的机器学习框架

Scikit-learn：算法库，用来辅助机器学习框架

Cuda/Numpy：在多维数组和矩阵上执行高级数学操作的库

SciPy：用于科学计算和技术计算的库

Pandas：分析和完成数据准备的库

---

## 单层LSTM细胞构建

```python
import tokenFile
import numpy as np

# 输出单元激活函数
def softmax(x):
	x = np.array(x)
	max_x = np.max(x)
	return np.exp(x-max_x)/np.sum(np.exp(x-max_x))

def sigmoid(x):
	return 1.0/(1.0 + np.exp(-x))

def tanh(x):
	return (np.exp(x) - np.exp(-x)) / (np.exp(x) + np.exp(-x))

class LSTMcell:
	def __init__(self, data_dim, hidden_dim=100):
		# 词向量维度，隐藏层维度
		self.data_dim = data_dim
		self.hidden_dim = hidden_dim

		#初始化权重向量 ...
		pass

	# 初始化wh, wx, b
	def _init_wh_wx(self):
		pass

	# 初始化各个状态的向量, 需要包含时间步步长
	def _init_s(self, T):
		pass

	# 计算门的输出
	def _cal_gate(self, wh, wx, b, ht_pre, x, activation):
		return activation(wh.dot(ht_pre) + wx[:, x].reshape(-1, 1) + b)


	# 前向传播，单个x
	def forward(self, x):
		# 代表向量时间长度
		T = len(x)
		# 初始化各个状态的向量
		stats = self._init_s(T)
		for t in range(T):
			# 前一刻隐藏状态
			ht_pre = np.array(stats['hss'][t-1]).reshape(-1, 1)
			# input gate
			stats['iss'][t] = self._cal_gate(self.whi, self.wxi, self.bi, ht_pre, x[t], sigmoid)
			# forget gate
			stats['fss'][t] = self._cal_gate(self.whf, self.wxf, self.bf, ht_pre, x[t], sigmoid)
			# ouput gate
			stats['oss'][t] = self._cal_gate(self.who, self.wxo, self.bo, ht_pre, x[t], sigmoid)
			# current input stats
			stats['ass'][t] = self._cal_gate(self.wha, self.wxa, self.ba, ht_pre, x[t], sigmoid)

			# cell stats, ct = ft * ct_pre + it * at
			stats['css'][t] = stats['fss'][t] * stats['css'][t-1] + stats['iss'][t] * stats['ass'][t]
			# hidden stats, ht = ot*tanh(ct)
			stats['hss'][t] = stats['oss'][t] * tanh(stats['css'][t])
			# output val yt = softmax(self.wy.dot(ht) + self.by)
			stats['ys'][t] = softmax(self.wy.dot(stats['hss'][t]) + self.by)
		return stats

	# 预测输出 单个x
	def predict(self, x):
		stats = self.forward(x)
		pre_y = np.argmax(stats['ys'].reshape(len(x), -1), axis=-1)
		return pre_y

	# 计算loss
	def loss(self, x, y):
		cost = 0
		for i in xrange(len(y)):
			stats = self.forward(x[i])
			# 取出每一时刻的预测值
			pre_yi = stats['ys'][xrange(len(y[i])), y[i]]
			cost -= np.sum(np.log(pre_yi))

		#统计所有y中词的个数，计算平均损失
		N = np.sum([len(yi) for yi in y])
		ave_loss = cost/N

		return ave_loss

	# 初始化偏导数
	def _init_wh_wx_grad(self):
		pass
	# 以(x,y)为一个样本求梯度, 反向传播
	def bptt(self, x, y):
		pass
	# 更新各权重矩阵的偏导数
	def _cal_grad_delta(self, dwh, dwx, db, delta_net, ht_pre, x):
		pass
	#更新权重矩阵
	def _update_wh_wx(self, learning_rate, wh, wx, b, dwh, db):
		pass
	# 以(x,y)为一个样本计算梯度, 并更新权重矩阵
	def sgd_step(self, x, y):
		pass
	#训练LSTM
	def train(self, x_train, y_train, learning_rate=0.05, n_epoch=5):
		losses = []
		num_examples = 0
		for epoch in xrange(n_epoch):
			for i in xrange(len(y_train)):
				self.sgd_step(x_train[i], y_train[i], learning_rate)
				num_examples += 1

			loss = self.loss(x_train, y_train)
			losses.append(loss)

			print('epoch {0}:loss = {1}'.format(epoch+1, loss))
			if len(loss)>1 and losses[-1]>losses[-2]:
				#出现梯度颠簸，loss扩大
				learning_rate *= 0.50
		print('done')
		return

if __name__ == '__main__':
	main()

```







-----

## 基本的tf-LSTM构建

1. 用pandas划分数据集，一般是80%训练集、10%验证集、10%测试集，或者没有测试集

   ```python
   X_train,X_test,y_train,y_test = train_test_split(features, labels, test_size=0.2, shuffle=False, random_state=42)
   ```

2. 设置shuffle=flase，**表示拆分数据集的时候是否混洗，混洗会搅乱事务的发生顺序，所以对于LSTM一般false**

3. 设置random_state以便每次运行此函数时有相同的输出

4. 指定超参数

   ```python
   epochs = 8  #epoch 迭代次数
   n_classes = 1  #对应此分类所作类的数量
   n_units = 200  #对应于lstm隐藏状态的大小
   n_features = 29  #数据集中的特征数量
   batch_size = 35 #每批次的大小，每批次会进行一次反向传播
   ```

5. 给批数据定义place-holders

   ```python
   xplaceholder= tf.placeholder('float',[None,n_features])  
   yplaceholder = tf.placeholder('float') 
   ```

6. 数据准备结束，模型构建

   ```python
   def recurrent_neural_network_model():  
       layer ={ 'weights': tf.Variable(tf.random_normal([n_units,n_classes])),'bias':tf.Variable(tf.random_normal([n_classes]))}  
       x = tf.split(xplaceholder, n_features, 1)  
       print(x)  
       lstm_cell = rnn.BasicLSTMCell(n_units)  
       outputs, states = rnn.static_rnn(lstm_cell, x, dtype=tf.float32)  
       output = tf.matmul(outputs[-1], layer['weights']) + layer['bias']  
       return output 
   ```

   1. 手动定义权重和偏差的shapes，分别使用shape[rnn_size，n_classes]和[n_classes]的随机值赋予TensorFlow变量'weight'和'bias'
   2. 需要将数据作为序列分配给 x 。为此将特征批处理沿着它的垂直维度分成29个切片，成为一个二位张量。每个切片就是作为LSTM层的输入给出的序列的元素，序列的一个元素的形状将是：（<batch_size>，1））
   3. 开始创建LSTM，此函数实例化所有门的变量
   4. outputs变量包含每个时间步后LSTM层的所有输出，states包含两个隐藏状态和最后状态的值。
   5. 们只使用'outputs [-1]'获取LSTM层的最后一个输出，并将它与先前定义的权重矩阵相乘，并将偏差值添加到它。结果值是前向传播的logit值（评定模型，**Odds的对数称之为Logit**）。
   6. 返回logit值，logit值需要转化为概率值来使用。

7. 训练模型

   ```python
   def train_neural_network():  
       #1  
       logit = recurrent_neural_network_model()  
       logit = tf.reshape(logit, [-1])  
       #3  
       cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logit, labels=yplaceholder))  
       optimizer = tf.train.AdamOptimizer().minimize(cost)  
       with tf.Session() as sess:  
           #6  
           tf.global_variables_initializer().run()  
           tf.local_variables_initializer().run()  
           #7  
           for epoch in range(epochs):  
               epoch_loss = 0 #8  
               i = 0  
               for i in range(int(len(X_train) / batch_size)): #10  
                   #11  
                   start = i  
                   end = i + batch_size  
                   #13  
                   batch_x = np.array(X_train[start:end])  
                   batch_y = np.array(y_train[start:end])  
                   #15  
                   _, c = sess.run([optimizer, cost], feed_dict={xplaceholder: batch_x, yplaceholder: batch_y})  
                   epoch_loss += c  
                   i += batch_size  
                   #18  
                   print('Epoch', epoch, 'completed out of', epochs, 'loss:', epoch_loss)  
                   pred = tf.round(tf.nn.sigmoid(logit)).eval({xplaceholder: np.array(X_test), yplaceholder: np.array(y_test)})  
                   #20  
                   f1 = f1_score(np.array(y_test), pred, average='macro')  
                   accuracy=accuracy_score(np.array(y_test), pred)  
                   recall = recall_score(y_true=np.array(y_test), y_pred= pred)  
                   precision = precision_score(y_true=np.array(y_test), y_pred=pred)  
                   #24  
                   print("F1 Score:", f1)  
                   print("Accuracy Score:",accuracy)  
                   print("Recall:", recall)  
                   print("Precision:", precision)  
                   train_neural_network() 
   ```

   1. 将接收到的logit值分配给变量，logit是激活的倒数，从而得到激活概率
   2. 将 logits矩阵 reshaping 为一个向量，因为当将它提供给损失函数时，**标签的shape和logits 的shape应该相等。**
   3.  #3 定义损失函数，二分类使用sigmoid_cross_entropy_with_logits，多分类使用softmax_cross_entropy_with_logits
   4. 使用一个Adam优化器
   5. #6到这里才开始tensorflow会话，初始化变量
   6. 根据之前定义的迭代次数来跑满迭代
   7. 每次epoch开始之前都要把loss设为0
   8. 定义变量 i ，为了将数据拆分为批次时跟踪开始和结束计算
   9. -
   10. 再跑一个遍历，直到batches达到计算阈值
   11. 使用'start'和'end'变量来跟踪数据在每次迭代中的分割位置。
   12. 使用'start'和'end'变量来跟踪数据在每次迭代中的分割位置。
   13. 在每次迭代中，将分别为“batch_x”和“batch_y”变量分配一批特征和标签。
   14. 在每次迭代中，将分别为“batch_x”和“batch_y”变量分配一批特征和标签。
   15. 在这一行中，告诉Tensorflow运行必要的子图来计算优化器和成本，**方法是将'batch_x'和'batch_y'变量中的值提供给 place_holders 提到的占位符。**结果，将计算优化器的值和成本，并分别分配给“throw-away”变量和“c”变量。
   16. 当前批处理的损失将添加到“epoch_loss”变量中。
   17. 此行有助于遍历每批数据（特征和标签）。
   18. 打印那个epoch的总损失
   19. 到此为止，训练将持续到epochs数达到阈值。
       将测试数据集提供给模型并告诉Tensorflow运行计算logit所需的子图的地方。然后通过sigmoid激活传递logit值来获得预测。四舍五入该值以删除预测值的小数位。
   20. 在这里计算F1得分。F1 Score是Precision和Recall的加权平均值。
   21. 计算准确度分数
   22. 计算召回。召回是正确预测的阳性观察与所有阳性观察的比率。
   23. 计算精确度。精确度是正确预测的阳性观察值与总预测阳性观察值的比率。
   24. 结束

------

## Loss

损失函数是用来估量**模型的输出**![[公式]](https://www.zhihu.com/equation?tex=%5Chat%7By%7D)与**真实值**![[公式]](https://www.zhihu.com/equation?tex=y)之间的差距，给模型的优化指引方向。模型的结构风险包括了经验风险和结构风险，损失函数是经验风险函数的核心部分：

![[公式]](https://www.zhihu.com/equation?tex=%5Chat%7B%5Ctheta%7D%3D%5Carg+%5Cmin+_%7B%5Ctheta%7D+%5Cfrac%7B1%7D%7BN%7D+%5Csum_%7Bi%3D1%7D%5E%7BN%7D+L%5Cleft%28y_%7Bi%7D%2C+f%5Cleft%28x_%7Bi%7D+%3B+%5Ctheta%5Cright%29%2B%5Clambda+%5CPhi%28%5Ctheta%29%5Cright%29+%5C%5C)

式中，前面的均值函数为**经验风险**，![[公式]](https://www.zhihu.com/equation?tex=L%5Cleft%28y_%7Bi%7D%2C+f%5Cleft%28x_%7Bi%7D+%3B+%5Ctheta%5Cright%29%5Cright%29)为损失函数，后面的项为**结构风险**，![[公式]](https://www.zhihu.com/equation?tex=%5CPhi%28%5Ctheta%29)衡量模型的复杂度

### 均方差损失（Mean Squared Error Loss）

均方差（Mean Squared Error，MSE）损失是机器学习、深度学习回归任务中最常用的一种损失函数，也称为 L2 Loss。其基本形式如下：

![[公式]](https://www.zhihu.com/equation?tex=J_%7BM+S+E%7D%3D%5Cfrac%7B1%7D%7BN%7D+%5Csum_%7Bi%3D1%7D%5E%7BN%7D%5Cleft%28y_%7Bi%7D-%5Chat%7By%7D_%7Bi%7D%5Cright%29%5E%7B2%7D+%5C%5C)

**背后的假设：**

实际上在一定的假设下，我们可以使用最大化似然得到均方差损失的形式。假设**模型预测与真实值之间的误差服从标准高斯分布**![[公式]](https://www.zhihu.com/equation?tex=%28%5Cmu%3D0%2C+%5Csigma%3D1%29)

### **交叉熵损失（Cross Entropy Loss）**

对于分类问题，最常用的损失函数是交叉熵损失函数（Cross Entropy Loss）

### **二分类：**

考虑二分类，在二分类中我们通常使用Sigmoid函数将模型的输出压缩到![[公式]](https://www.zhihu.com/equation?tex=%280%2C1%29)区间内，![[公式]](https://www.zhihu.com/equation?tex=%5Chat%7By%7D_%7Bi%7D+%5Cin%280%2C1%29)，用来代表给定输入![[公式]](https://www.zhihu.com/equation?tex=%7Bx%7D_%7Bi%7D)，模型判断为正类的概率。由于只有正负两类，因此同时也得到了负类的概率：

![[公式]](https://www.zhihu.com/equation?tex=p%5Cleft%28y_%7Bi%7D%3D1+%7C+x_%7Bi%7D%5Cright%29%3D%5Chat%7By%7D_%7Bi%7D+%5C%5C)![[公式]](https://www.zhihu.com/equation?tex=p%5Cleft%28y_%7Bi%7D%3D0+%7C+x_%7Bi%7D%5Cright%29%3D1-%5Chat%7By%7D_%7Bi%7D+%5C%5C)

将两条式子合并成一条：

![[公式]](https://www.zhihu.com/equation?tex=p%5Cleft%28y_%7Bi%7D+%7C+x_%7Bi%7D%5Cright%29%3D%5Cleft%28%5Chat%7By%7D_%7Bi%7D%5Cright%29%5E%7By_%7Bi%7D%7D%5Cleft%281-%5Chat%7By%7D_%7Bi%7D%5Cright%29%5E%7B1-y_%7Bi%7D%7D+%5C%5C)

假设数据点之间独立同分布，则似然可以表示为：

![[公式]](https://www.zhihu.com/equation?tex=L%28x%2C+y%29%3D%5Cprod_%7Bi%3D1%7D%5E%7BN%7D%5Cleft%28%5Chat%7By%7D_%7Bi%7D%5Cright%29%5E%7By_%7Bi%7D%7D%5Cleft%281-%5Chat%7By%7D_%7Bi%7D%5Cright%29%5E%7B1-y_%7Bi%7D%7D+%5C%5C)

对似然取对数，然后加负号变成最小化负对数似然，即为交叉熵损失函数的形式：

![[公式]](https://www.zhihu.com/equation?tex=N+L+L%28x%2C+y%29%3DJ_%7BC+E%7D%3D-%5Csum_%7Bi%3D1%7D%5E%7BN%7D+y_%7Bi%7D+%5Clog+%5Cleft%28%5Chat%7By%7D_%7Bi%7D%5Cright%29%2B%5Cleft%281-y_%7Bi%7D%5Cright%29+%5Clog+%5Cleft%281-%5Chat%7By%7D_%7Bi%7D%5Cright%29+%5C%5C)

### 多分类的交叉熵

损失函数的推导思路和二分类是一样的，变化的地方是真实值![[公式]](https://www.zhihu.com/equation?tex=y_%7Bi%7D)是一个One-hot 向量，同时模型输出的压缩由原来的Sigmoid函数换成Softmax函数。Softmax 函数将每个维度的输出范围都限定在![[公式]](https://www.zhihu.com/equation?tex=%280%2C1%29)之间，同时所有维度的输出和为1，用于表示一个概率分布

![[公式]](https://www.zhihu.com/equation?tex=p%5Cleft%28y_%7Bi%7D+%7C+x_%7Bi%7D%5Cright%29%3D%5Cprod_%7Bk%3D1%7D%5E%7BK%7D%5Cleft%28%5Chat%7By%7D_%7Bi%7D%5E%7Bk%7D%5Cright%29%5E%7By_%7Bi%7D%5E%7Bk%7D%7D+%5C%5C)

其中，![[公式]](https://www.zhihu.com/equation?tex=k+%5Cin+K)表示K个类别中的一类，同样的假设数据点之间独立同分布，可得到负对数似然为：

![[公式]](https://www.zhihu.com/equation?tex=N+L+L%28x%2C+y%29%3DJ_%7BC+E%7D%3D-%5Csum_%7Bi%3D1%7D%5E%7BN%7D+%5Csum_%7Bk%3D1%7D%5E%7BK%7D+y_%7Bi%7D%5E%7Bk%7D+%5Clog+%5Cleft%28%5Chat%7By%7D_%7Bi%7D%5E%7Bk%7D%5Cright%29+%5C%5C)

由于![[公式]](https://www.zhihu.com/equation?tex=y_%7Bi%7D)是一个One-hot向量，除了目标类为1之外其他类别上的输出都为 0，因此上式也可以写为：

![[公式]](https://www.zhihu.com/equation?tex=J_%7BC+E%7D%3D-%5Csum_%7Bi%3D1%7D%5E%7BN%7D+y_%7Bi%7D%5E%7Bc_%7Bi%7D%7D+%5Clog+%5Cleft%28y_%7Bi%7D%5E%7B%5Chat%7Bc%7D_%7Bi%7D%7D%5Cright%29+%5C%5C)

其中，![[公式]](https://www.zhihu.com/equation?tex=c_%7Bi%7D)是![[公式]](https://www.zhihu.com/equation?tex=x_%7Bi%7D)的目标类，通常这个应用于多分类的交叉熵损失函数也被称为Softmax Loss或者Categorical Cross Entropy Loss

### 其他Loss

1. MAE 平均绝对误差损失**Mean Absolute Error Loss** 
2. Huber Loss
3. 分位数损失（Quantile Loss）
4. 合页损失（Hinge Loss）
5. 0/1损失函数
6. 指数损失 
7. 对数损失/对数似然损失（Log-likelihood Loss）

来源：https://zhuanlan.zhihu.com/p/97698386

---





------

## Dropout

指的就是在神经网络的训练过程中提出的一种防止过拟合的策略。

旨在训练过程中按照一定的概率（一般情况下：隐藏层采样概率为0.5，输入层采样概率为0.8）随机删除网络中的神经元（输出层除外）。

深度神经网络在悬链的过程中总会遇到两大缺点：

1. 过拟合
2. 时间过长，爆炸

**Dropout**可以被认为是集成大量深层神经网络的实用的Bagging方法。

为什么能防止过拟合

1. 取平均的作用，使用相同的数据集去训练5个不同的神经网络，一般会得到5个不同的结果，此时我们可以采用**“求平均的”**或者**“多数得胜”**的策略来决定最终的结果。因为不同的子结构会产生不同的过拟合情况，取平均可能将“相反”的你和相互抵消。从而使得整个网络减少过拟合程度。
2. **减少神经元之间复杂的共适应关系**，Dropout技术使得某两个神经元不一定每次都在一个子网络结构中出现。基于此权值的更新不在依赖于固定关系的隐含节点的共同作用，**阻止了某些特征仅仅在其他特征下才能有效的情况。**迫使网络去学习更加鲁棒的特征（更加具有通适性）。
3. Dropout类比于性别生物进化中的角色，取平均是Dropout产生了许多子结构之后的操作，父神经网络有N个节点，加入Dropout之后可以看做在权值不变的情况下（参数共享）将模型数量扩增到指数级别。 反过来想，如果要训练2N个参数的模型，如果没有加入Dropout，则需要费2N的时间去训练。加入Dropout之后则只需要训练N个参数的时间即可得到2N参数效果的模型。这不就是省时了么>_>

------

## 优化

一般需要优化病态矩阵，条件数很大的[非奇异矩阵](https://baike.baidu.com/item/非奇异矩阵)。**病态矩阵的逆和以其为系数矩阵的方程组的界对微小扰动十分敏感，对数值求解会带来很大困难。** 

出现变态矩阵的话，如果元素改变一点点结果就会变化很大。

主要有Tikhonov、[奇异值](https://baike.baidu.com/item/奇异值/9975162)截断、奇异值修正、[迭代法](https://baike.baidu.com/item/迭代法/10913188)等方法。

### 奇异值截断分解TSVD

和PCA很像，只是**SVD分解是在数据矩阵上进行，而PCA是在数据的协方差矩阵上进行**。通常，SVD用于发现矩阵的主成份。

TSVD与一般SVD不同的是它可以产生一个指定维度的分解矩阵。例如，有一个矩阵，通过SVD分解后仍然是一个矩阵，而TSVD可以生成指定维度的矩阵。这样就可以实现**降维**了。

```python
from sklearn.decomposition import TruncatedSVD
 
svd = TruncatedSVD(2)
iris_transformed = svd.fit_transform(iris_data)
iris_data[:5]
```

### SGDM

也就是SGD+ Momentum。这里引入了**一阶动量**。
 **从直观理解就是加入了一个惯性，在坡度比较陡的地方，会有较大的惯性，这是下降的多。坡度平缓的地方，惯性较小，下降的会比较慢。**
 修改SGD中的一阶动量为
![math?formula=m_t%3D%5Cbeta_1%20*m_%7Bt-1%7D%2B(1-%5Cbeta_%7B1%7D)*g_%7Bt%7D](https://math.jianshu.com/math?formula=m_t%3D%5Cbeta_1%20*m_%7Bt-1%7D%2B%281-%5Cbeta_%7B1%7D%29*g_%7Bt%7D)![math?formula=m_t%3D%5Cbeta_1%20*m_%7Bt-1%7D%2B(1-%5Cbeta_%7B1%7D)*g_%7Bt%7D](https://math.jianshu.com/math?formula=m_t%3D%5Cbeta_1%20*m_%7Bt-1%7D%2B%281-%5Cbeta_%7B1%7D%29*g_%7Bt%7D)!![m_t=\beta_1 *m_{t-1}+(1-\beta_{1})*g_{t}](https://math.jianshu.com/math?formula=m_t%3D%5Cbeta_1%20*m_%7Bt-1%7D%2B%281-%5Cbeta_%7B1%7D%29*g_%7Bt%7D)
 等式右边有两部分，加号左边的部分为之前积累的下降方向，加号右边为当前的梯度。两者的权重用参数来控制。
![\beta](https://math.jianshu.com/math?formula=%5Cbeta)越大，说明下降的方向越依赖于以往的惯性。可以减少方向的突变。

### AdaGrad

**为每一个参数保留一个学习率以提升在稀疏梯度（即自然语言和计算机视觉问题）上的性能**

![img](https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy8yMDg0NTQyLTM4Mjk5Y2IwY2UzZGRiNzkucG5n?x-oss-process=image/format,png)

![img](https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy8xMDA0NjgxNC0zNDJhMTY5NDQ5ZDNiNTQxLnBuZz9pbWFnZU1vZ3IyL2F1dG8tb3JpZW50L3N0cmlwJTdDaW1hZ2VWaWV3Mi8yL3cvMzExL2Zvcm1hdC93ZWJw?x-oss-process=image/format,png)

gt表示第t时间步的梯度（向量，包含各个参数对应的偏导数，gt,i表示第i个参数t时刻偏导数）

gt2表示第t时间步的梯度平方（向量，由gt各元素自己进行平方运算所得，即Element-wise）

与SGD的核心区别在于计算更新步长时，增加了分母：**梯度平方累积和的平方根**。此项能够累积各个参数gt,i的历史梯度平方，频繁更新的梯度，则累积的分母项逐渐偏大，那么更新的步长(stepsize)相对就会变小，而稀疏的梯度，则导致累积的分母项中对应值比较小，那么更新的步长则相对比较大。

**AdaGrad能够自动为不同参数适应不同的学习率（平方根的分母项相当于对学习率α进进行了自动调整，然后再乘以本次梯度）**，大多数的框架实现采用默认学习率α=0.01即可完成比较好的收敛。

优势：在数据分布稀疏的场景，能更好利用稀疏梯度的信息，比标准的SGD算法更有效地收敛。

缺点：主要缺陷来自分母项的对梯度平方不断累积，随之时间步地增加，分母项越来越大，最终导致**学习率收缩到太小无法进行有效更新。**

------

## 如何判断出现了过拟合和欠拟合

过拟合：训练集拟合很好，但是测试集、验证集拟合不足

欠拟合：训练集和验证集皆拟合不足

在训练之前应该使用少量数据训练一个更小的模型，等这个模型泛化比较好的时候再去训练更深更大的网络。

具体设计网络的过程可以参考 **Residual Net** 和 **Wide Residual Net**

----

## 为什么会出现梯度消失和梯度爆炸

沿梯度方向时，方向导数取得最大值，计算速度最快。

> 因此，在求解损失函数的最小值时，可以通过梯度下降法来一步步的迭代求解，得到最小化的损失函数和模型参数值。**梯度下降法的计算过程就是沿梯度下降的方向求解极小值。**当梯度向量为零，说明到达一个极值点，这也是梯度下降算法迭代计算的终止条件。

梯度不稳定的根本原因：前面层上的梯度是来自后面层上梯度的乘积。**如果当前层数过多，就容易出现梯度不稳定**

在网络中，靠近输入层的隐藏层细胞就容易出现梯度不稳定。

梯度消失：做反向传播的时候需要计算损失函数对权重的梯度，发现越向后面传播，梯度变得越来越小。**这就意味着网络前面的一些层的细胞会比后面训练的慢得多，甚至不会变化**。

梯度爆炸：与上述情况相反，前面靠近输入层的细胞训练速率暴涨，而且梯度变化剧烈，甚至出现梯度颠簸的情况。

### 实际出现过的原因

梯度消失：

1. 隐藏层层数过多
2. 采用的激活函数不适当（sigmoid函数使用不当就会出现梯度消失）

梯度爆炸：

1. 隐藏层层数过多
2. 权重的初始化值过大
3. 激活函数导数大于1，也有可能使梯度呈指数级增长

### 解决方案

要不就解决连乘效应，要不就适应连乘效应

1. 用ReLU、Maxout等激活函数代替sigmoid函数，缓解梯度消失问题
2. 用Batch Normalization进行归一化处理，通过对每一层的输出规范为均值和使方差一致的方法，**能够消除缩放操作**带来的影响。
3. LSTM可以稍微缓解梯度消失的问题

特定的解决方案

**梯度消失**

1. 逐层**预训练**，对整个网络进行微调，耗费人工时间
2. 改变激活函数
3. 使用残差结构
4. LSTM

**梯度爆炸**

1. 反向传播的时候进行梯度剪枝
2. 输入权重正则化
3. 改变激活函数
4. 在RNN上改进：规定一个back out time，在反向传播的时候通过时间强行截断
5. 也可以使用LSTM，但是LSTM处理梯度爆炸需要自己设计异常检测模型。